# -*- coding: utf-8 -*-
import sys
import os
import cv2
import numpy as np
import time

# å¼•å…¥ AclLite åº“ (è¯·ç¡®ä¿ acllite æ–‡ä»¶å¤¹åœ¨å½“å‰ç›®å½•æˆ– PYTHONPATH ä¸­)
# åä¸º CANN Samples é€šå¸¸æä¾›è¿™ä¸ªå°è£…åº“
from acllite.acllite_model import AclLiteModel
from acllite.acllite_resource import AclLiteResource

# ================= é…ç½®åŒºåŸŸ =================
# 1. æ¨¡å‹è·¯å¾„ (è¯·ä¿®æ”¹ä¸ºä½ è½¬å¥½çš„ .om æ–‡ä»¶å)
YOLOX_MODEL_PATH = "./yolox_plate.om" 
LPR_MODEL_PATH = "./lprnet.om"
IMAGE_PATH = "./test.jpg"
OUTPUT_TXT_PATH = "./output.txt"
print(f"ğŸ“ è¯†åˆ«ç»“æœå°†è®°å½•åˆ°: {OUTPUT_TXT_PATH}")
# 2. LPRNet å‚æ•° (å¿…é¡»å’Œè®­ç»ƒä¿æŒä¸€è‡´)
# å¦‚æœä½ æœ€åç”¨çš„æ˜¯ 160å®½ï¼Œè¯·æ”¹ä¸º 160
LPR_WIDTH = 160 
LPR_HEIGHT = 24

# 3. å­—å…¸ (66ç±»ï¼Œå»æ‰äº† I å’Œ O)
CHARS = [
    'äº¬','æ²ª','æ´¥','æ¸','å†€','æ™‹','è’™','è¾½','å‰','é»‘',
    'è‹','æµ™','çš–','é—½','èµ£','é²','è±«','é„‚','æ¹˜','ç²¤',
    'æ¡‚','ç¼','å·','è´µ','äº‘','è—','é™•','ç”˜','é’','å®',
    'æ–°',
    '0','1','2','3','4','5','6','7','8','9',
    'A','B','C','D','E','F','G','H','J','K',
    'L','M','N','P','Q','R','S','T','U','V',
    'W','X','Y','Z',
    '-'
]

# ================= å·¥å…·å‡½æ•° =================

def preprocess_yolox(img, input_size=(640, 640)):
    """YOLOX é¢„å¤„ç†: Resize + Pad (ä¸å½’ä¸€åŒ–)"""
    padded_img = np.ones((input_size[0], input_size[1], 3), dtype=np.uint8) * 114
    r = min(input_size[0] / img.shape[0], input_size[1] / img.shape[1])
    resized_img = cv2.resize(
        img, (int(img.shape[1] * r), int(img.shape[0] * r)), interpolation=cv2.INTER_LINEAR
    ).astype(np.uint8)
    padded_img[: int(img.shape[0] * r), : int(img.shape[1] * r)] = resized_img
    
    # HWC -> CHW, float32
    blob = padded_img.transpose(2, 0, 1).astype(np.float32)
    # ã€Atlaså…³é”®ã€‘å†…å­˜å¿…é¡»è¿ç»­
    blob = np.ascontiguousarray(blob)
    return blob, r

def nms(boxes, scores, nms_thr):
    """éæå¤§å€¼æŠ‘åˆ¶"""
    x1 = boxes[:, 0]
    y1 = boxes[:, 1]
    x2 = boxes[:, 2]
    y2 = boxes[:, 3]
    areas = (x2 - x1 + 1) * (y2 - y1 + 1)
    order = scores.argsort()[::-1]
    keep = []
    while order.size > 0:
        i = order[0]
        keep.append(i)
        xx1 = np.maximum(x1[i], x1[order[1:]])
        yy1 = np.maximum(y1[i], y1[order[1:]])
        xx2 = np.minimum(x2[i], x2[order[1:]])
        yy2 = np.minimum(y2[i], y2[order[1:]])
        w = np.maximum(0.0, xx2 - xx1 + 1)
        h = np.maximum(0.0, yy2 - yy1 + 1)
        inter = w * h
        ovr = inter / (areas[i] + areas[order[1:]] - inter)
        inds = np.where(ovr <= nms_thr)[0]
        order = order[inds + 1]
    return keep

def decode_lpr(preds):
    """CTC è´ªå©ªè§£ç """
    res = []
    for i in range(len(preds)):
        idx = preds[i]
        # 65 æ˜¯ç©ºç™½ç¬¦ '-' çš„ç´¢å¼•
        if idx == len(CHARS) - 1: continue 
        # å»é‡
        if i > 0 and idx == preds[i-1]: continue 
        res.append(CHARS[idx])
    return "".join(res)

# ================= ä¸»é€»è¾‘ =================

def main():
    # 0. èµ„æºåˆå§‹åŒ–
    acl_resource = AclLiteResource()
    acl_resource.init()
    
    # 1. åŠ è½½æ¨¡å‹
    print(f"ğŸš€ åŠ è½½æ¨¡å‹...\n YOLOX: {YOLOX_MODEL_PATH}\n LPRNet: {LPR_MODEL_PATH}")
    if not os.path.exists(YOLOX_MODEL_PATH) or not os.path.exists(LPR_MODEL_PATH):
        print("âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„ï¼")
        return

    model_yolo = AclLiteModel(YOLOX_MODEL_PATH)
    model_lpr = AclLiteModel(LPR_MODEL_PATH)
    

    

    # 2. è¯»å–å›¾ç‰‡
    src_img = cv2.imread(IMAGE_PATH)
    if src_img is None:
        print(f"âŒ è¯»å–å›¾ç‰‡å¤±è´¥: {IMAGE_PATH}")
        return

    # ----------------------------------------------------
    # Step A: YOLOX æ£€æµ‹
    # ----------------------------------------------------
    t0 = time.time()
    yolo_input_size = (640, 640)
    img_in, ratio = preprocess_yolox(src_img, yolo_input_size)
    
    # æ¨ç† (è¾“å…¥å¿…é¡»æ˜¯ list)
    yolo_result_list = model_yolo.execute([img_in[None, :]]) 
    
    # è·å–è¾“å‡º (1, 8400, 6) -> å·²ç»æ˜¯è§£ç åçš„ç»å¯¹åæ ‡
    predictions = yolo_result_list[0][0] 
    
    # åæ ‡è½¬æ¢: cx,cy,w,h -> x1,y1,x2,y2
    boxes_xywh = predictions[:, :4]
    boxes_xyxy = np.ones_like(boxes_xywh)
    boxes_xyxy[:, 0] = boxes_xywh[:, 0] - boxes_xywh[:, 2]/2.
    boxes_xyxy[:, 1] = boxes_xywh[:, 1] - boxes_xywh[:, 3]/2.
    boxes_xyxy[:, 2] = boxes_xywh[:, 0] + boxes_xywh[:, 2]/2.
    boxes_xyxy[:, 3] = boxes_xywh[:, 1] + boxes_xywh[:, 3]/2.
    
    scores = predictions[:, 4] * predictions[:, 5]
    
    # ç­›é€‰
    mask = scores > 0.7  # æé«˜é˜ˆå€¼è¿‡æ»¤å‡è½¦ç‰Œ
    dets = boxes_xyxy[mask]
    scores = scores[mask]
    
    final_boxes = []
    if len(dets) > 0:
        keep = nms(dets, scores, 0.45)
        final_boxes = dets[keep]
        print(f"âœ… YOLOX æ£€æµ‹åˆ° {len(final_boxes)} ä¸ªç›®æ ‡ (è€—æ—¶ {time.time()-t0:.4f}s)")
    else:
        print("âš ï¸ æœªæ£€æµ‹åˆ°è½¦ç‰Œ")
    
    # ----------------------------------------------------
    # Step B: LPRNet è¯†åˆ«
    # ----------------------------------------------------
    for i, box in enumerate(final_boxes):
        # 1. åæ ‡è¿˜åŸ
        box /= ratio
        x1, y1, x2, y2 = box.astype(int)
        
        # 2. Padding (ä¼˜åŒ–åçš„ç­–ç•¥)
        w_box, h_box = x2 - x1, y2 - y1
        pad_w = int(w_box * 0.06) # å·¦å³å¤šç•™ç‚¹ï¼Œé˜²æ­¢åˆ‡æ‰çœä»½
        pad_h = int(h_box * 0.04)
        
        x1 = max(0, x1 - pad_w)
        y1 = max(0, y1 - pad_h)
        x2 = min(src_img.shape[1], x2 + pad_w)
        y2 = min(src_img.shape[0], y2 + pad_h)
        
        # 3. æŠ å›¾
        plate_img = src_img[y1:y2, x1:x2]
        if plate_img.size == 0: continue
        
        # 4. LPR é¢„å¤„ç† (å¿…é¡»å’Œè®­ç»ƒä¸€è‡´: å½©è‰² + Resize + Norm)
        # æ³¨æ„: ä½¿ç”¨ INTER_CUBIC æå‡æ¸…æ™°åº¦
        lpr_img = cv2.resize(plate_img, (LPR_WIDTH, LPR_HEIGHT), interpolation=cv2.INTER_CUBIC)
        lpr_img = lpr_img.astype('float32')
        lpr_img -= 127.5
        lpr_img *= 0.0078125
        
        # HWC -> CHW
        lpr_img = lpr_img.transpose(2, 0, 1)
        lpr_img = np.ascontiguousarray(lpr_img) # å†…å­˜è¿ç»­
        
        # 5. æ¨ç†
        t_lpr = time.time()
        lpr_result_list = model_lpr.execute([lpr_img[None, :]])
        lpr_output = lpr_result_list[0][0] # [66, 24] æˆ– [24, 66]
        
        # 6. ç»´åº¦è‡ªåŠ¨åˆ¤æ–­
        class_dim = -1
        if lpr_output.shape[0] == 66: class_dim = 0
        elif lpr_output.shape[1] == 66: class_dim = 1
        
        if class_dim == -1: raw_preds = np.argmax(lpr_output, axis=0) # ç›²çŒœ
        else: raw_preds = np.argmax(lpr_output, axis=class_dim)
        
        # 7. è§£ç 
        text = decode_lpr(raw_preds)
        
        # 8. ç®€å•è¿‡æ»¤
        if len(text) < 7:
            print(f"   [è¿‡æ»¤] ç»“æœå¤ªçŸ­: {text}")
            continue
            
        print(f"ğŸš— è½¦ç‰Œ {i+1}: {text} (LPRè€—æ—¶ {time.time()-t_lpr:.4f}s)")

        try:
        # ä½¿ç”¨ 'a' æ¨¡å¼ï¼šå¦‚æœæ–‡ä»¶ä¸å­˜åœ¨åˆ™åˆ›å»ºï¼Œå­˜åœ¨åˆ™è¿½åŠ å†™å…¥
            with open(OUTPUT_TXT_PATH, 'a', encoding='utf-8') as f:
            # å†™å…¥å†…å®¹ï¼šå¯ä»¥åŒ…å«æ—¶é—´æˆ³å’Œè½¦ç‰Œå·
               current_time = time.strftime("%Y-%m-%d %H:%M:%S", time.localtime())
               record_line = f"[{current_time}] æ£€æµ‹åˆ°è½¦ç‰Œ: {text}\n"
               f.write(record_line)
               print(f"   ğŸ’¾ å·²è®°å½•åˆ°æ–‡ä»¶")
        except Exception as e:
            print(f"   âŒ å†™å…¥æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        
        # 9. ç»˜å›¾ (åœ¨æ¿å­ä¸Šè·‘å¦‚æœä¸æ¥æ˜¾ç¤ºå™¨ï¼Œè¿™ä¸€æ­¥ä¸»è¦æ˜¯ä¿å­˜çœ‹ç»“æœ)
        cv2.rectangle(src_img, (x1, y1), (x2, y2), (0, 255, 0), 2)
        # PutText ä¸æ”¯æŒä¸­æ–‡ï¼Œåªæ˜¾ç¤ºååŠéƒ¨åˆ†æˆ–æ‹¼éŸ³ï¼Œæˆ–è€…å¹²è„†ä¸å†™
        cv2.putText(src_img, text, (x1, y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)

    # ä¿å­˜ç»“æœå›¾
    cv2.imwrite("result_atlas.jpg", src_img)
    print("ğŸ’¾ ç»“æœå·²ä¿å­˜è‡³ result_atlas.jpg")

if __name__ == '__main__':
    main()